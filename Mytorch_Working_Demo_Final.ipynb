{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Uploading and extracting Mytorch.zip**"
      ],
      "metadata": {
        "id": "eGfxlzaefqy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# upload Mytorch.zip file here\n",
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "id": "q9HKafKhfpnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extracts Mytorch\n",
        "import zipfile\n",
        "zip_file_name = 'Mytorch.zip'\n",
        "extract_location = '/content/'\n",
        "\n",
        "with zipfile.ZipFile(zip_file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_location)"
      ],
      "metadata": {
        "id": "RY2guaXbYtpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Imports from Mytroch:**"
      ],
      "metadata": {
        "id": "uDuRiSaYf5q_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import Mytorch\n",
        "import Mytorch.Network.Network as Network\n",
        "from Mytorch.ActivationFunctions import Sigmoid,Tanh,ReLU,LeakyReLU,Softmax\n",
        "from Mytorch.Layers import FCLayer\n",
        "from Mytorch.LossFunctions import BinaryCrossEntropy, CrossEntropy, MeanSquaredError\n",
        "from Mytorch.Optimizers import GradientDescent, GradientDescentWithMomentum, RMSProp, Adam\n"
      ],
      "metadata": {
        "id": "BNtzGKs_ZVLq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Creating Network:**\n",
        "\n",
        "Network Archetecture:\n",
        "\n",
        "\n",
        "```\n",
        "fullyconnecedlayer(inputsize=784,output_size=100)\n",
        "tanh activation layer()\n",
        "fullyconnectedlayer(input_size=100,output_size=50)\n",
        "tanh activation layer()\n",
        "fullyconnectedlayer(input_size=50, output_size=10)\n",
        "tanh activation layer()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "arJC4H19gEbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "net = Network()\n",
        "net.add_layers(FCLayer(28*28, 100))\n",
        "net.add_layers(Tanh())\n",
        "net.add_layers(FCLayer(100,50))\n",
        "net.add_layers(Tanh())\n",
        "net.add_layers(FCLayer(50, 10))\n",
        "net.add_layers(Softmax())"
      ],
      "metadata": {
        "id": "GBwAQCYUFMrB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#accuracy function\n",
        "def accuracy(pred,true):\n",
        "    return np.sum(true==pred,axis=0)/len(true)"
      ],
      "metadata": {
        "id": "_bQcl9rsGM58"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading MNIST handwritten digit dataset from pytorch**\n",
        "\n",
        "we're using pytorch only to load dataset.\n",
        "\n"
      ],
      "metadata": {
        "id": "PHCO74rzhEhQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "import torch\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "\n",
        "\n",
        "def to_one_hot(labels, num_classes=10):\n",
        "    one_hot_labels = torch.zeros(labels.size(0), num_classes)\n",
        "    for i, label in enumerate(labels):\n",
        "        one_hot_labels[i][label] = 1.0\n",
        "    return one_hot_labels"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JO2gIjUhGU2T",
        "outputId": "9dac4d0c-a0f0-4392-cbbe-df0d2a936fc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 124086228.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 17018220.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "100%|██████████| 1648877/1648877 [00:00<00:00, 31586047.28it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5220753.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training:**"
      ],
      "metadata": {
        "id": "uyxc53zHhgSa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "learning_rate= 0.001\n",
        "optimizer=GradientDescent(net.layers,learning_rate=learning_rate)\n",
        "error=BinaryCrossEntropy()\n",
        "epochs=5\n",
        "for epoch in range(epochs):\n",
        "    epoch_loss=[]\n",
        "    acc=[]\n",
        "    for images,labels in train_loader:\n",
        "        data=images.reshape(images.shape[0],1,28*28)\n",
        "        targets=to_one_hot(labels)\n",
        "        data=data.numpy()\n",
        "        targets=targets.numpy()\n",
        "        outputs=net.predict(data)\n",
        "        loss=error.Loss(targets,outputs)\n",
        "        epoch_loss.append(loss)\n",
        "        acc.append(accuracy(np.argmax(outputs,axis=1),np.argmax(targets,axis=1)))\n",
        "        error.backward(net,targets,outputs)\n",
        "        optimizer.step()\n",
        "\n",
        "    print(f\"epoch:{epoch+1}, loss:{np.mean(epoch_loss)} , accuracy:{np.mean(acc)*100}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTk50oTCGDML",
        "outputId": "9ef76eb5-18d8-435b-ee36-126e7f28a36e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch:1, loss:0.05534357757459145 , accuracy:90.18666666666667%\n",
            "epoch:2, loss:0.029554867894933914 , accuracy:94.87166666666667%\n",
            "epoch:3, loss:0.02261124664236384 , accuracy:96.13166666666667%\n",
            "epoch:4, loss:0.018698921618208766 , accuracy:96.79333333333334%\n",
            "epoch:5, loss:0.015679072729489714 , accuracy:97.28833333333333%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing on test dataset:**"
      ],
      "metadata": {
        "id": "uDkrvd3YhmtM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "acc=[]\n",
        "for image,labels in test_loader:\n",
        "    data=image.reshape(image.shape[0],1,28*28)\n",
        "    targets=to_one_hot(labels)\n",
        "    data=data.numpy()\n",
        "    targets=targets.numpy()\n",
        "    outputs=net.predict(data)\n",
        "    acc.append(accuracy(np.argmax(outputs,axis=1),np.argmax(targets,axis=1)))\n",
        "\n",
        "print(f\"test accuracy: {np.mean(acc)*100}\")\n"
      ],
      "metadata": {
        "id": "m3ZGIpv4Fi7N",
        "outputId": "871bd834-eb66-4565-9399-70a36ef90268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test accuracy: 96.765525477707\n"
          ]
        }
      ]
    }
  ]
}